{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db188d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from Amazon_Fashion_merged.parquet\n",
      "Loading from Software_merged.parquet\n",
      "Loading from Health_and_Personal_Care_merged.parquet\n",
      "Loading from Musical_Instruments_merged.parquet\n",
      "Loading from Home_and_Kitchen_merged.parquet\n",
      "Skipped /root/cleaned_parquets/Home_and_Kitchen_merged.parquet: Invalid Input Error: No magic bytes found at end of file '/root/cleaned_parquets/Home_and_Kitchen_merged.parquet'\n",
      "Loading from Handmade_Products_merged.parquet\n",
      "Loading from Unknown_merged.parquet\n",
      "Skipped /root/cleaned_parquets/Unknown_merged.parquet: Invalid Input Error: No magic bytes found at end of file '/root/cleaned_parquets/Unknown_merged.parquet'\n",
      "Loading from Electronics_merged.parquet\n",
      "Loading from Patio_Lawn_and_Garden_merged.parquet\n",
      "Loading from Office_Products_merged.parquet\n",
      "Loading from Kindle_Store_merged.parquet\n",
      "Skipped /root/cleaned_parquets/Kindle_Store_merged.parquet: Invalid Input Error: No magic bytes found at end of file '/root/cleaned_parquets/Kindle_Store_merged.parquet'\n",
      "Loading from Clothing_Shoes_and_Jewelry_merged.parquet\n",
      "Skipped /root/cleaned_parquets/Clothing_Shoes_and_Jewelry_merged.parquet: Invalid Input Error: No magic bytes found at end of file '/root/cleaned_parquets/Clothing_Shoes_and_Jewelry_merged.parquet'\n",
      "Loading from Health_and_Household_merged.parquet\n",
      "Loading from Movies_and_TV_merged.parquet\n",
      "Skipped /root/cleaned_parquets/Movies_and_TV_merged.parquet: Invalid Input Error: No magic bytes found at end of file '/root/cleaned_parquets/Movies_and_TV_merged.parquet'\n",
      "Loading from Grocery_and_Gourmet_Food_merged.parquet\n",
      "Loading from Pet_Supplies_merged.parquet\n",
      "Loading from Industrial_and_Scientific_merged.parquet\n",
      "Loading from Sports_and_Outdoors_merged.parquet\n",
      "Loading from Toys_and_Games_merged.parquet\n",
      "Loading from Tools_and_Home_Improvement_merged.parquet\n",
      "Loading from Magazine_Subscriptions_merged.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/venv/lib/python3.12/site-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 4 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n",
      "/root/venv/lib/python3.12/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed coo_matrix instead. Converting to CSR took 0.03084564208984375 seconds\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [01:01<00:00,  4.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Sample Recommendations:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "user_items must contain 1 row for every user in userids",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m user_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(user_map.keys())[:\u001b[32m3\u001b[39m]:\n\u001b[32m     47\u001b[39m     user_idx = user_map[user_id]\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     recs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecommend\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratings_matrix_csr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUser \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[\u001b[38;5;28mlist\u001b[39m(item_map.keys())[i]\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mi,\u001b[38;5;250m \u001b[39m_\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mrecs]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.12/site-packages/implicit/cpu/matrix_factorization_base.py:49\u001b[39m, in \u001b[36mMatrixFactorizationBase.recommend\u001b[39m\u001b[34m(self, userid, user_items, N, filter_already_liked_items, filter_items, recalculate_user, items)\u001b[39m\n\u001b[32m     47\u001b[39m     user_count = \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.isscalar(userid) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(userid)\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m user_items.shape[\u001b[32m0\u001b[39m] != user_count:\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33muser_items must contain 1 row for every user in userids\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     51\u001b[39m user = \u001b[38;5;28mself\u001b[39m._user_factor(userid, user_items, recalculate_user)\n\u001b[32m     53\u001b[39m item_factors = \u001b[38;5;28mself\u001b[39m.item_factors\n",
      "\u001b[31mValueError\u001b[39m: user_items must contain 1 row for every user in userids"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.sparse import coo_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "CLEANED_DIR = \"/root/cleaned_parquets\"\n",
    "all_files = glob.glob(os.path.join(CLEANED_DIR, \"*_merged.parquet\"))\n",
    "\n",
    "df_list = []\n",
    "\n",
    "# Load relevant data in batches\n",
    "for file in all_files:\n",
    "    print(f\"Loading from {os.path.basename(file)}\")\n",
    "    try:\n",
    "        df = duckdb.sql(f\"\"\"\n",
    "            SELECT user_id, asin, rating\n",
    "            FROM '{file}'\n",
    "            WHERE rating BETWEEN 1 AND 5\n",
    "            LIMIT 50000\n",
    "        \"\"\").df()\n",
    "        df_list.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipped {file}: {e}\")\n",
    "\n",
    "# Combine all batches\n",
    "df = pd.concat(df_list, ignore_index=True).dropna()\n",
    "\n",
    "# Encode IDs\n",
    "user_map = {u: i for i, u in enumerate(df['user_id'].unique())}\n",
    "item_map = {a: j for j, a in enumerate(df['asin'].unique())}\n",
    "df['user_idx'] = df['user_id'].map(user_map)\n",
    "df['item_idx'] = df['asin'].map(item_map)\n",
    "\n",
    "# Create sparse matrix (item-user for training)\n",
    "ratings_matrix = coo_matrix((df['rating'], (df['user_idx'], df['item_idx'])))\n",
    "ratings_matrix_csr = ratings_matrix.tocsr()\n",
    "\n",
    "# Train ALS\n",
    "model = AlternatingLeastSquares(factors=50, iterations=15, regularization=0.1)\n",
    "model.fit(ratings_matrix.T)  # transpose = item-user\n",
    "\n",
    "# Recommend for 3 users\n",
    "print(\"Sample Recommendations:\")\n",
    "for user_id in list(user_map.keys())[:3]:\n",
    "    user_idx = user_map[user_id]\n",
    "    user_ratings = ratings_matrix_csr[user_idx]  # ðŸ”¥ Extract only that user's row\n",
    "    recs = model.recommend(user_idx, user_ratings, N=5)\n",
    "    item_ids = [list(item_map.keys())[i] for i, _ in recs]\n",
    "    print(f\"User {user_id}: {item_ids}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
