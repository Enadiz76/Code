{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81d9d035",
   "metadata": {},
   "source": [
    "# COMP 3610 – A3\n",
    "\n",
    "- Zidane Timothy, Maia Neptune, Christophe Gittens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d06bc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pyspark\n",
    "# %pip install findspark\n",
    "# %pip install -q gdown\n",
    "# %pip install pandas\n",
    "# %pip install matplotlib\n",
    "# %pip install seaborn\n",
    "# %pip install pyarrow\n",
    "# %pip install setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f66dda25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "# import `DenseVector`\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "\n",
    "# import `StandardScaler`\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "\n",
    "# sudo apt install python3-distutils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "645f1318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pathlib import Path\n",
    "import os\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "import time, matplotlib.pyplot as plt, seaborn as sns, matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed40f4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd04f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark = SparkSession.builder\\\n",
    "# .appName(\"Amazon_Reviews\")\\\n",
    "# .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c33973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_schema = StructType([\n",
    "    StructField(\"rating\", FloatType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"images\", ArrayType(StringType()), True),\n",
    "    StructField(\"asin\", StringType(), True),\n",
    "    StructField(\"parent_asin\", FloatType(), True),\n",
    "    StructField(\"user_id\", ArrayType(StringType()), True),\n",
    "    StructField(\"timestamp\", IntegerType(), True),\n",
    "    StructField(\"verified_purchase\", BooleanType(), True),\n",
    "    StructField(\"helpful_vote\", StringType(), True),\n",
    "])\n",
    "\n",
    "# String types in arrays may need to be sequence but couldn't find the actual sequence dytpe syntax\n",
    "meta_schema = StructType([\n",
    "    StructField(\"main_category\", StringType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"average_rating\", FloatType(), True),\n",
    "    StructField(\"rating_number\", IntegerType(), True),\n",
    "    StructField(\"features\", ArrayType(StringType()), True),\n",
    "    StructField(\"description\", ArrayType(StringType()), True),\n",
    "    StructField(\"price\", FloatType(), True),\n",
    "    StructField(\"images\", ArrayType(StringType()), True),\n",
    "    StructField(\"videos\", ArrayType(StringType()), True),\n",
    "    StructField(\"store\", StringType(), True),\n",
    "    StructField(\"categories\", ArrayType(StringType()), True),\n",
    "    StructField(\"details\", MapType(StringType(), IntegerType()), True),\n",
    "    StructField(\"parent_asin\", FloatType(), True),\n",
    "    StructField(\"user_id\", ArrayType(StringType()), True),\n",
    "    StructField(\"bought_together\", ArrayType(StringType()), True),\n",
    "    # StructField(\"timestamp\", IntegerType(), True),\n",
    "    # StructField(\"verified_purchase\", BooleanType(), True),\n",
    "    # StructField(\"helpful_vote\", StringType(), True),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a217ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_folder = 'root/Data'\n",
    "output_folder = 'root/output_folder'\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9aeafd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tar_bz2(tar_path, extract_dir):\n",
    "    if not os.path.exists(tar_path):\n",
    "        print(f\"Error: File {tar_path} does not exist.\")\n",
    "        return\n",
    "    if not tar_path.endswith(\".tar.bz2\"):\n",
    "        print(f\"Error: File {tar_path} is not a .tar.bz2 file.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with tarfile.open(tar_path, \"r:bz2\") as tar:\n",
    "            print(f\"Extracting {tar_path} to {extract_dir}\")\n",
    "            tar.extractall(path=extract_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during extraction: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed93461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# from datasets import load_dataset\n",
    "# from pathlib import Path\n",
    "# import pyarrow as pa\n",
    "# import pyarrow.parquet as pq\n",
    "\n",
    "# def preprocess_category(review_tar_path, meta_tar_path, output_folder, batch_size=1000):\n",
    "#     temp_path = \"root/Data/temp_extract\"\n",
    "#     if os.path.exists(temp_path):\n",
    "#         shutil.rmtree(temp_path)\n",
    "#     os.makedirs(temp_path, exist_ok=True)\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "#     print(\"Extracting tar files...\")\n",
    "#     extract_tar_bz2(review_tar_path, temp_path)\n",
    "#     extract_tar_bz2(meta_tar_path, temp_path)\n",
    "\n",
    "#     arrow_files = list(Path(temp_path).rglob(\"*.arrow\"))\n",
    "#     print(f\"Found {len(arrow_files)} Arrow files\")\n",
    "\n",
    "#     for arrow_file in arrow_files:\n",
    "#         try:\n",
    "#             is_meta = \"meta\" in str(arrow_file).lower()\n",
    "#             output_path = os.path.join(output_folder, \"meta.parquet\" if is_meta else \"reviews.parquet\")\n",
    "#             os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "#             print(f\"Streaming {arrow_file.name} → {output_path}\")\n",
    "#             dataset = load_dataset(\"arrow\", data_files=str(arrow_file), split=\"train\", streaming=True)\n",
    "\n",
    "#             # once the dataset has been loaded we can clean it HERE one time\n",
    "\n",
    "#             batch = []\n",
    "#             for i, row in enumerate(dataset):\n",
    "#                 batch.append(row)\n",
    "#                 if len(batch) >= batch_size:\n",
    "#                     table = pa.Table.from_pylist(batch)\n",
    "#                     pq.write_to_dataset(table, root_path=output_path)\n",
    "#                     print(f\"Wrote batch of {len(batch)} rows to {output_path}\")\n",
    "#                     batch = []\n",
    "\n",
    "#             if batch:\n",
    "#                 table = pa.Table.from_pylist(batch)\n",
    "#                 pq.write_to_dataset(table, root_path=output_path) \n",
    "#                 print(f\"Wrote final batch of {len(batch)} rows to {output_path}\")\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing {arrow_file.name}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29758b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review_row(row):\n",
    "    # Drop if rating is invalid\n",
    "    if \"rating\" not in row or not (1 <= row[\"rating\"] <= 5):\n",
    "        return None\n",
    "\n",
    "    # Drop if review text is empty\n",
    "    if not row.get(\"text\") or not str(row[\"text\"]).strip():\n",
    "        return None\n",
    "\n",
    "    # Brand extraction fallback\n",
    "    details = row.get(\"details\", {})\n",
    "    brand = None\n",
    "    if isinstance(details, dict):\n",
    "        brand = details.get(\"brand\")\n",
    "    if not brand:\n",
    "        brand = row.get(\"store\")\n",
    "    row[\"brand\"] = brand or \"Unknown\"\n",
    "\n",
    "    # Add review_length\n",
    "    row[\"review_length\"] = len(str(row.get(\"text\", \"\")).split())\n",
    "\n",
    "    # Add year from timestamp\n",
    "    ts = row.get(\"timestamp\")\n",
    "    try:\n",
    "        row[\"year\"] = datetime.utcfromtimestamp(ts).year if ts else None\n",
    "    except:\n",
    "        row[\"year\"] = None\n",
    "\n",
    "    # Cast helpful_vote to int if needed\n",
    "    if \"helpful_vote\" in row:\n",
    "        try:\n",
    "            row[\"helpful_vote\"] = int(row[\"helpful_vote\"])\n",
    "        except:\n",
    "            row[\"helpful_vote\"] = 0\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30755800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_meta_row(row):\n",
    "    # normalize nested fields to string\n",
    "    complex_fields = [\"features\", \"description\", \"images\", \"videos\", \"categories\", \"details\", \"bought_together\"]\n",
    "    for field in complex_fields:\n",
    "        if field in row and isinstance(row[field], (dict, list)):\n",
    "            try:\n",
    "                row[field] = json.dumps(row[field])\n",
    "            except:\n",
    "                row[field] = None\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23a7ac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# from datasets import load_dataset\n",
    "# from pathlib import Path\n",
    "# import pyarrow as pa\n",
    "# import pyarrow.parquet as pq\n",
    "\n",
    "# def preprocess_category(review_tar_path, meta_tar_path, output_folder, batch_size=1000):\n",
    "#     temp_path = \"root/Data/temp_extract\"\n",
    "#     if os.path.exists(temp_path):\n",
    "#         shutil.rmtree(temp_path)\n",
    "#     os.makedirs(temp_path, exist_ok=True)\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "#     print(\"Extracting tar files...\")\n",
    "#     extract_tar_bz2(review_tar_path, temp_path)\n",
    "#     extract_tar_bz2(meta_tar_path, temp_path)\n",
    "\n",
    "#     arrow_files = list(Path(temp_path).rglob(\"*.arrow\"))\n",
    "#     print(f\"Found {len(arrow_files)} Arrow files\")\n",
    "\n",
    "#     for arrow_file in arrow_files:\n",
    "#             try:\n",
    "#                 is_meta = \"meta\" in str(arrow_file).lower()\n",
    "#                 output_path = os.path.join(output_folder, \"meta.parquet\" if is_meta else \"reviews.parquet\")\n",
    "#                 os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "#                 print(f\"Streaming {arrow_file.name} → {output_path}\")\n",
    "#                 dataset = load_dataset(\"arrow\", data_files=str(arrow_file), split=\"train\", streaming=True)\n",
    "\n",
    "#                 batch = []\n",
    "#                 seen_keys = set()  # For deduplication\n",
    "\n",
    "#                 for i, row in enumerate(dataset):\n",
    "#                     # Clean row depending on type\n",
    "#                     #row = clean_meta_row(row) if is_meta else clean_review_row(row)\n",
    "\n",
    "#                     if not row:\n",
    "#                         continue\n",
    "\n",
    "#                     # Deduplicate reviews on (user_id, asin, text)\n",
    "#                     if not is_meta:\n",
    "#                         key = (row.get(\"user_id\"), row.get(\"asin\"), row.get(\"text\"))\n",
    "#                         if key in seen_keys:\n",
    "#                             continue\n",
    "#                         seen_keys.add(key)\n",
    "\n",
    "#                     batch.append(row)\n",
    "\n",
    "#                     if len(batch) >= batch_size:\n",
    "#                         table = pa.Table.from_pylist(batch)\n",
    "#                         pq.write_to_dataset(table, root_path=output_path)\n",
    "#                         print(f\"Wrote batch of {len(batch)} rows to {output_path}\")\n",
    "#                         batch = []\n",
    "\n",
    "#                 if batch:\n",
    "#                     table = pa.Table.from_pylist(batch)\n",
    "#                     pq.write_to_dataset(table, root_path=output_path)\n",
    "#                     print(f\"Wrote final batch of {len(batch)} rows to {output_path}\")\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing {arrow_file.name}: {e}\")\n",
    "\n",
    "#     shutil.rmtree(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8066e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_category(review_tar_path, meta_tar_path, output_folder, batch_size=1000):\n",
    "    temp_path = \"root/Data/temp_extract\"\n",
    "    if os.path.exists(temp_path):\n",
    "        shutil.rmtree(temp_path)\n",
    "    os.makedirs(temp_path, exist_ok=True)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    print(\"Extracting tar files...\")\n",
    "    extract_tar_bz2(review_tar_path, temp_path)\n",
    "    extract_tar_bz2(meta_tar_path, temp_path)\n",
    "\n",
    "    arrow_files = list(Path(temp_path).rglob(\"*.arrow\"))\n",
    "    print(f\"Found {len(arrow_files)} Arrow files\")\n",
    "\n",
    "    for arrow_file in arrow_files:\n",
    "        try:\n",
    "            is_meta = \"meta\" in str(arrow_file).lower()\n",
    "            folder_name = \"meta\" if is_meta else \"reviews\"\n",
    "\n",
    "            parquet_output_path = os.path.join(output_folder, f\"{folder_name}.parquet\")\n",
    "            pkl_output_path = os.path.join(output_folder, f\"{folder_name}_pkl\")\n",
    "            os.makedirs(parquet_output_path, exist_ok=True)\n",
    "            os.makedirs(pkl_output_path, exist_ok=True)\n",
    "\n",
    "            print(f\"Streaming {arrow_file.name} → {parquet_output_path}\")\n",
    "            dataset = load_dataset(\"arrow\", data_files=str(arrow_file), split=\"train\", streaming=True)\n",
    "\n",
    "            batch = []\n",
    "            seen_keys = set()\n",
    "            batch_num = 0\n",
    "\n",
    "            for i, row in enumerate(dataset):\n",
    "                if not row:\n",
    "                    continue\n",
    "\n",
    "                if not is_meta:\n",
    "                    key = (row.get(\"user_id\"), row.get(\"asin\"), row.get(\"text\"))\n",
    "                    if key in seen_keys:\n",
    "                        continue\n",
    "                    seen_keys.add(key)\n",
    "\n",
    "                batch.append(row)\n",
    "\n",
    "                if len(batch) >= batch_size:\n",
    "                    table = pa.Table.from_pylist(batch)\n",
    "                    pq.write_to_dataset(table, root_path=parquet_output_path)\n",
    "\n",
    "                    # convert to pandas and save as .pkl batch\n",
    "                    df = pd.DataFrame(batch)\n",
    "                    df.to_pickle(os.path.join(pkl_output_path, f\"batch_{batch_num}.pkl\"))\n",
    "                    print(f\"Saved batch {batch_num} ({len(batch)} rows) to .parquet and .pkl\")\n",
    "                    batch = []\n",
    "                    batch_num += 1\n",
    "\n",
    "            # Final batch\n",
    "            if batch:\n",
    "                table = pa.Table.from_pylist(batch)\n",
    "                pq.write_to_dataset(table, root_path=parquet_output_path)\n",
    "\n",
    "                df = pd.DataFrame(batch)\n",
    "                df.to_pickle(os.path.join(pkl_output_path, f\"batch_{batch_num}.pkl\"))\n",
    "                print(f\"Saved final batch {batch_num} ({len(batch)} rows)\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {arrow_file.name}: {e}\")\n",
    "\n",
    "    shutil.rmtree(temp_path)\n",
    "    print(\"All done, temp folder removed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40019db",
   "metadata": {},
   "source": [
    "Calling fn to preprocess for a category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190dcc23",
   "metadata": {},
   "source": [
    "Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2bfa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tar files...\n",
      "Extracting /root/Data/raw_meta_Amazon_Fashion.tar.bz2 to root/Data/temp_extract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_154197/2872024491.py:12: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall(path=extract_dir)\n"
     ]
    }
   ],
   "source": [
    "preprocess_category(\n",
    "    \"/root/Data/raw_meta_Amazon_Fashion.tar.bz2\",\n",
    "    \"/root/Data/raw_review_Amazon_Fashion.tar.bz2\",\n",
    "    \"/root/Data/output_folder\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4062c9",
   "metadata": {},
   "source": [
    "Appliances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61f8edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tar files...\n",
      "Error: File root/Data/raw_meta_Appliances.tar.bz2 does not exist.\n",
      "Error: File root/Datraw_review_Appliances.tar.bz2 does not exist.\n",
      "Found 0 Arrow files\n",
      "All done, temp folder removed.\n"
     ]
    }
   ],
   "source": [
    "preprocess_category(\n",
    "    \"/root/Data/raw_meta_Appliances.tar.bz2\",\n",
    "    \"/root/Data/raw_review_Appliances.tar.bz2\",\n",
    "    \"/root/output_folder\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9220f981",
   "metadata": {},
   "source": [
    "Load the parquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefb961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"SPARK_LOCAL_IP\"] = \"10.17.0.5\"\n",
    "\n",
    "# reviews = pd.read_parquet(r\"root/output_folder/reviews.parquet\", engine=\"pyarrow\")\n",
    "# meta = pd.read_parquet(r\"root/output_folder/meta.parquet\")\n",
    "\n",
    "# merged = pd.merge(reviews, meta, on=\"parent_asin\", how=\"inner\")\n",
    "# merged.to_parquet(r\"root/output_folder/merged_cleaned.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c53fed",
   "metadata": {},
   "source": [
    "Testing - For Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccd9d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"/root/output_folder/meta\"  # Make sure this is the folder with .pkl batches\n",
    "df_m = []\n",
    "\n",
    "for fname in sorted(os.listdir(folder)):\n",
    "    if fname.endswith(\".pkl\"):\n",
    "        try:\n",
    "            file_path = os.path.join(folder, fname)\n",
    "            meta_df = pd.read_pickle(file_path)\n",
    "            print(f\"{fname} loaded: shape = {meta_df.shape}\")\n",
    "            df_m.append(meta_df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in {fname}:\", e)\n",
    "\n",
    "if df_m:\n",
    "    full_meta_Amazon_df = pd.concat(df_m, ignore_index=True)\n",
    "    print(\"All .pkl files loaded. Final shape:\", full_meta_Amazon_df.shape)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d96bf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_177.pkl loaded: shape = (1000, 13)\n",
      "batch_178.pkl loaded: shape = (1000, 13)\n",
      "batch_179.pkl loaded: shape = (1000, 13)\n",
      "batch_18.pkl loaded: shape = (1000, 13)\n",
      "batch_180.pkl loaded: shape = (1000, 13)\n",
      "batch_181.pkl loaded: shape = (1000, 13)\n",
      "batch_182.pkl loaded: shape = (1000, 13)\n",
      "batch_183.pkl loaded: shape = (1000, 13)\n",
      "batch_184.pkl loaded: shape = (1000, 13)\n",
      "batch_185.pkl loaded: shape = (1000, 13)\n",
      "batch_186.pkl loaded: shape = (1000, 13)\n",
      "batch_187.pkl loaded: shape = (1000, 13)\n",
      "batch_188.pkl loaded: shape = (1000, 13)\n",
      "batch_189.pkl loaded: shape = (1000, 13)\n",
      "batch_19.pkl loaded: shape = (1000, 13)\n",
      "batch_190.pkl loaded: shape = (1000, 13)\n",
      "batch_191.pkl loaded: shape = (1000, 13)\n",
      "batch_192.pkl loaded: shape = (1000, 13)\n",
      "batch_193.pkl loaded: shape = (1000, 13)\n",
      "batch_194.pkl loaded: shape = (1000, 13)\n",
      "batch_195.pkl loaded: shape = (1000, 13)\n",
      "batch_196.pkl loaded: shape = (1000, 13)\n",
      "batch_197.pkl loaded: shape = (1000, 13)\n",
      "batch_198.pkl loaded: shape = (1000, 13)\n",
      "batch_199.pkl loaded: shape = (1000, 13)\n",
      "batch_2.pkl loaded: shape = (1000, 13)\n",
      "batch_20.pkl loaded: shape = (1000, 13)\n",
      "batch_200.pkl loaded: shape = (1000, 13)\n",
      "batch_201.pkl loaded: shape = (1000, 13)\n",
      "batch_202.pkl loaded: shape = (1000, 13)\n",
      "batch_203.pkl loaded: shape = (1000, 13)\n",
      "batch_204.pkl loaded: shape = (1000, 13)\n",
      "batch_205.pkl loaded: shape = (1000, 13)\n",
      "batch_206.pkl loaded: shape = (1000, 13)\n",
      "batch_207.pkl loaded: shape = (1000, 13)\n",
      "batch_208.pkl loaded: shape = (1000, 13)\n",
      "batch_209.pkl loaded: shape = (1000, 13)\n",
      "batch_21.pkl loaded: shape = (1000, 13)\n",
      "batch_210.pkl loaded: shape = (1000, 13)\n",
      "batch_211.pkl loaded: shape = (1000, 13)\n",
      "batch_212.pkl loaded: shape = (1000, 13)\n",
      "batch_213.pkl loaded: shape = (1000, 13)\n",
      "batch_214.pkl loaded: shape = (1000, 13)\n",
      "batch_215.pkl loaded: shape = (1000, 13)\n",
      "batch_216.pkl loaded: shape = (1000, 13)\n",
      "batch_217.pkl loaded: shape = (1000, 13)\n",
      "batch_218.pkl loaded: shape = (1000, 13)\n",
      "batch_219.pkl loaded: shape = (1000, 13)\n",
      "batch_22.pkl loaded: shape = (1000, 13)\n",
      "batch_220.pkl loaded: shape = (1000, 13)\n",
      "batch_221.pkl loaded: shape = (1000, 13)\n",
      "batch_222.pkl loaded: shape = (1000, 13)\n",
      "batch_223.pkl loaded: shape = (1000, 13)\n",
      "batch_224.pkl loaded: shape = (1000, 13)\n",
      "batch_225.pkl loaded: shape = (1000, 13)\n",
      "batch_226.pkl loaded: shape = (1000, 13)\n",
      "batch_227.pkl loaded: shape = (1000, 13)\n",
      "batch_228.pkl loaded: shape = (1000, 13)\n",
      "batch_229.pkl loaded: shape = (1000, 13)\n",
      "batch_23.pkl loaded: shape = (1000, 13)\n",
      "batch_230.pkl loaded: shape = (1000, 13)\n",
      "batch_231.pkl loaded: shape = (1000, 13)\n",
      "batch_232.pkl loaded: shape = (1000, 13)\n",
      "batch_233.pkl loaded: shape = (1000, 13)\n",
      "batch_234.pkl loaded: shape = (1000, 13)\n",
      "batch_235.pkl loaded: shape = (1000, 13)\n",
      "batch_236.pkl loaded: shape = (1000, 13)\n",
      "batch_237.pkl loaded: shape = (1000, 13)\n",
      "batch_238.pkl loaded: shape = (1000, 13)\n",
      "batch_239.pkl loaded: shape = (1000, 13)\n",
      "batch_24.pkl loaded: shape = (1000, 13)\n",
      "batch_240.pkl loaded: shape = (1000, 13)\n",
      "batch_241.pkl loaded: shape = (1000, 13)\n",
      "batch_242.pkl loaded: shape = (1000, 13)\n",
      "batch_243.pkl loaded: shape = (1000, 13)\n",
      "batch_244.pkl loaded: shape = (1000, 13)\n",
      "batch_245.pkl loaded: shape = (1000, 13)\n",
      "batch_246.pkl loaded: shape = (1000, 13)\n",
      "batch_247.pkl loaded: shape = (1000, 13)\n",
      "batch_248.pkl loaded: shape = (1000, 13)\n",
      "batch_249.pkl loaded: shape = (1000, 13)\n",
      "batch_25.pkl loaded: shape = (1000, 13)\n",
      "batch_250.pkl loaded: shape = (1000, 13)\n",
      "batch_251.pkl loaded: shape = (1000, 13)\n",
      "batch_252.pkl loaded: shape = (1000, 13)\n",
      "batch_253.pkl loaded: shape = (1000, 13)\n",
      "batch_254.pkl loaded: shape = (1000, 13)\n",
      "batch_255.pkl loaded: shape = (1000, 13)\n",
      "batch_256.pkl loaded: shape = (1000, 13)\n",
      "batch_257.pkl loaded: shape = (1000, 13)\n",
      "batch_258.pkl loaded: shape = (1000, 13)\n",
      "batch_259.pkl loaded: shape = (1000, 13)\n",
      "batch_26.pkl loaded: shape = (1000, 13)\n",
      "batch_260.pkl loaded: shape = (1000, 13)\n",
      "batch_261.pkl loaded: shape = (1000, 13)\n",
      "batch_262.pkl loaded: shape = (1000, 13)\n",
      "batch_263.pkl loaded: shape = (1000, 13)\n",
      "batch_264.pkl loaded: shape = (1000, 13)\n",
      "batch_265.pkl loaded: shape = (1000, 13)\n",
      "batch_266.pkl loaded: shape = (1000, 13)\n",
      "batch_267.pkl loaded: shape = (1000, 13)\n",
      "batch_268.pkl loaded: shape = (1000, 13)\n",
      "batch_269.pkl loaded: shape = (1000, 13)\n",
      "batch_27.pkl loaded: shape = (1000, 13)\n",
      "batch_270.pkl loaded: shape = (1000, 13)\n",
      "batch_271.pkl loaded: shape = (1000, 13)\n",
      "batch_272.pkl loaded: shape = (1000, 13)\n",
      "batch_273.pkl loaded: shape = (1000, 13)\n",
      "batch_274.pkl loaded: shape = (1000, 13)\n",
      "batch_275.pkl loaded: shape = (1000, 13)\n",
      "batch_276.pkl loaded: shape = (1000, 13)\n",
      "batch_277.pkl loaded: shape = (1000, 13)\n",
      "batch_278.pkl loaded: shape = (1000, 13)\n",
      "batch_279.pkl loaded: shape = (1000, 13)\n",
      "batch_28.pkl loaded: shape = (1000, 13)\n",
      "batch_280.pkl loaded: shape = (1000, 13)\n",
      "batch_281.pkl loaded: shape = (1000, 13)\n",
      "batch_282.pkl loaded: shape = (1000, 13)\n",
      "batch_283.pkl loaded: shape = (1000, 13)\n",
      "batch_284.pkl loaded: shape = (1000, 13)\n",
      "batch_285.pkl loaded: shape = (1000, 13)\n",
      "batch_286.pkl loaded: shape = (1000, 13)\n",
      "batch_287.pkl loaded: shape = (1000, 13)\n",
      "batch_288.pkl loaded: shape = (1000, 13)\n",
      "batch_289.pkl loaded: shape = (1000, 13)\n",
      "batch_29.pkl loaded: shape = (1000, 13)\n",
      "batch_290.pkl loaded: shape = (1000, 13)\n",
      "batch_291.pkl loaded: shape = (1000, 13)\n",
      "batch_292.pkl loaded: shape = (1000, 13)\n",
      "batch_293.pkl loaded: shape = (1000, 13)\n",
      "batch_294.pkl loaded: shape = (1000, 13)\n",
      "batch_295.pkl loaded: shape = (1000, 13)\n",
      "batch_296.pkl loaded: shape = (1000, 13)\n",
      "batch_297.pkl loaded: shape = (1000, 13)\n",
      "batch_298.pkl loaded: shape = (1000, 13)\n",
      "batch_299.pkl loaded: shape = (1000, 13)\n",
      "batch_3.pkl loaded: shape = (1000, 13)\n",
      "batch_30.pkl loaded: shape = (1000, 13)\n",
      "batch_300.pkl loaded: shape = (1000, 13)\n",
      "batch_301.pkl loaded: shape = (1000, 13)\n",
      "batch_302.pkl loaded: shape = (1000, 13)\n",
      "batch_303.pkl loaded: shape = (1000, 13)\n",
      "batch_304.pkl loaded: shape = (1000, 13)\n",
      "batch_305.pkl loaded: shape = (1000, 13)\n",
      "batch_306.pkl loaded: shape = (1000, 13)\n",
      "batch_307.pkl loaded: shape = (1000, 13)\n",
      "batch_308.pkl loaded: shape = (1000, 13)\n",
      "batch_309.pkl loaded: shape = (1000, 13)\n",
      "batch_31.pkl loaded: shape = (1000, 13)\n",
      "batch_310.pkl loaded: shape = (1000, 13)\n",
      "batch_311.pkl loaded: shape = (1000, 13)\n",
      "batch_312.pkl loaded: shape = (1000, 13)\n",
      "batch_313.pkl loaded: shape = (1000, 13)\n",
      "batch_314.pkl loaded: shape = (1000, 13)\n",
      "batch_315.pkl loaded: shape = (1000, 13)\n",
      "batch_316.pkl loaded: shape = (1000, 13)\n",
      "batch_317.pkl loaded: shape = (1000, 13)\n",
      "batch_318.pkl loaded: shape = (1000, 13)\n",
      "batch_319.pkl loaded: shape = (1000, 13)\n",
      "batch_32.pkl loaded: shape = (1000, 13)\n",
      "batch_320.pkl loaded: shape = (1000, 13)\n",
      "batch_321.pkl loaded: shape = (1000, 13)\n",
      "batch_322.pkl loaded: shape = (1000, 13)\n",
      "batch_323.pkl loaded: shape = (1000, 13)\n",
      "batch_324.pkl loaded: shape = (1000, 13)\n",
      "batch_325.pkl loaded: shape = (1000, 13)\n",
      "batch_326.pkl loaded: shape = (1000, 13)\n",
      "batch_327.pkl loaded: shape = (1000, 13)\n",
      "batch_328.pkl loaded: shape = (1000, 13)\n",
      "batch_329.pkl loaded: shape = (1000, 13)\n",
      "batch_33.pkl loaded: shape = (1000, 13)\n",
      "batch_330.pkl loaded: shape = (1000, 13)\n",
      "batch_331.pkl loaded: shape = (1000, 13)\n",
      "batch_332.pkl loaded: shape = (1000, 13)\n",
      "batch_333.pkl loaded: shape = (1000, 13)\n",
      "batch_334.pkl loaded: shape = (1000, 13)\n",
      "batch_335.pkl loaded: shape = (1000, 13)\n",
      "batch_336.pkl loaded: shape = (1000, 13)\n",
      "batch_337.pkl loaded: shape = (1000, 13)\n",
      "batch_338.pkl loaded: shape = (1000, 13)\n",
      "batch_339.pkl loaded: shape = (1000, 13)\n",
      "batch_34.pkl loaded: shape = (1000, 13)\n",
      "batch_340.pkl loaded: shape = (1000, 13)\n",
      "batch_341.pkl loaded: shape = (1000, 13)\n",
      "batch_342.pkl loaded: shape = (1000, 13)\n",
      "batch_343.pkl loaded: shape = (1000, 13)\n",
      "batch_344.pkl loaded: shape = (1000, 13)\n",
      "batch_345.pkl loaded: shape = (1000, 13)\n",
      "batch_346.pkl loaded: shape = (1000, 13)\n",
      "batch_347.pkl loaded: shape = (1000, 13)\n",
      "batch_348.pkl loaded: shape = (1000, 13)\n",
      "batch_349.pkl loaded: shape = (1000, 13)\n",
      "batch_35.pkl loaded: shape = (1000, 13)\n",
      "batch_350.pkl loaded: shape = (1000, 13)\n",
      "batch_351.pkl loaded: shape = (1000, 13)\n",
      "batch_352.pkl loaded: shape = (1000, 13)\n",
      "batch_353.pkl loaded: shape = (1000, 13)\n",
      "batch_354.pkl loaded: shape = (1000, 13)\n",
      "batch_355.pkl loaded: shape = (1000, 13)\n",
      "batch_356.pkl loaded: shape = (1000, 13)\n",
      "batch_357.pkl loaded: shape = (1000, 13)\n",
      "batch_358.pkl loaded: shape = (1000, 13)\n",
      "batch_359.pkl loaded: shape = (1000, 13)\n",
      "batch_36.pkl loaded: shape = (1000, 13)\n",
      "batch_360.pkl loaded: shape = (1000, 13)\n",
      "batch_361.pkl loaded: shape = (1000, 13)\n",
      "batch_362.pkl loaded: shape = (1000, 13)\n",
      "batch_363.pkl loaded: shape = (1000, 13)\n",
      "batch_364.pkl loaded: shape = (1000, 13)\n",
      "batch_365.pkl loaded: shape = (1000, 13)\n",
      "batch_366.pkl loaded: shape = (1000, 13)\n",
      "batch_367.pkl loaded: shape = (1000, 13)\n",
      "batch_368.pkl loaded: shape = (1000, 13)\n",
      "batch_369.pkl loaded: shape = (1000, 13)\n",
      "batch_37.pkl loaded: shape = (1000, 13)\n",
      "batch_370.pkl loaded: shape = (1000, 13)\n",
      "batch_371.pkl loaded: shape = (1000, 13)\n",
      "batch_372.pkl loaded: shape = (1000, 13)\n",
      "batch_373.pkl loaded: shape = (1000, 13)\n",
      "batch_374.pkl loaded: shape = (1000, 13)\n",
      "batch_375.pkl loaded: shape = (1000, 13)\n",
      "batch_376.pkl loaded: shape = (1000, 13)\n",
      "batch_377.pkl loaded: shape = (1000, 13)\n",
      "batch_378.pkl loaded: shape = (1000, 13)\n",
      "batch_379.pkl loaded: shape = (1000, 13)\n",
      "batch_38.pkl loaded: shape = (1000, 13)\n",
      "batch_380.pkl loaded: shape = (1000, 13)\n",
      "batch_381.pkl loaded: shape = (1000, 13)\n",
      "batch_382.pkl loaded: shape = (1000, 13)\n",
      "batch_383.pkl loaded: shape = (1000, 13)\n",
      "batch_384.pkl loaded: shape = (1000, 13)\n",
      "batch_385.pkl loaded: shape = (1000, 13)\n",
      "batch_386.pkl loaded: shape = (1000, 13)\n",
      "batch_387.pkl loaded: shape = (1000, 13)\n",
      "batch_388.pkl loaded: shape = (1000, 13)\n",
      "batch_389.pkl loaded: shape = (1000, 13)\n",
      "batch_39.pkl loaded: shape = (1000, 13)\n",
      "batch_390.pkl loaded: shape = (1000, 13)\n",
      "batch_391.pkl loaded: shape = (1000, 13)\n",
      "batch_392.pkl loaded: shape = (1000, 13)\n",
      "batch_393.pkl loaded: shape = (1000, 13)\n",
      "batch_394.pkl loaded: shape = (1000, 13)\n",
      "batch_395.pkl loaded: shape = (1000, 13)\n",
      "batch_396.pkl loaded: shape = (1000, 13)\n",
      "batch_397.pkl loaded: shape = (1000, 13)\n",
      "batch_398.pkl loaded: shape = (1000, 13)\n",
      "batch_399.pkl loaded: shape = (1000, 13)\n",
      "batch_4.pkl loaded: shape = (1000, 13)\n",
      "batch_40.pkl loaded: shape = (1000, 13)\n",
      "batch_400.pkl loaded: shape = (1000, 13)\n",
      "batch_401.pkl loaded: shape = (1000, 13)\n",
      "batch_402.pkl loaded: shape = (1000, 13)\n",
      "batch_403.pkl loaded: shape = (1000, 13)\n",
      "batch_404.pkl loaded: shape = (1000, 13)\n",
      "batch_405.pkl loaded: shape = (1000, 13)\n",
      "batch_406.pkl loaded: shape = (1000, 13)\n",
      "batch_407.pkl loaded: shape = (1000, 13)\n",
      "batch_408.pkl loaded: shape = (1000, 13)\n",
      "batch_409.pkl loaded: shape = (1000, 13)\n",
      "batch_41.pkl loaded: shape = (1000, 13)\n",
      "batch_410.pkl loaded: shape = (1000, 13)\n",
      "batch_411.pkl loaded: shape = (1000, 13)\n",
      "batch_412.pkl loaded: shape = (1000, 13)\n",
      "batch_413.pkl loaded: shape = (1000, 13)\n",
      "batch_414.pkl loaded: shape = (1000, 13)\n",
      "batch_415.pkl loaded: shape = (1000, 13)\n",
      "batch_416.pkl loaded: shape = (1000, 13)\n",
      "batch_417.pkl loaded: shape = (1000, 13)\n",
      "batch_418.pkl loaded: shape = (1000, 13)\n",
      "batch_419.pkl loaded: shape = (1000, 13)\n",
      "batch_42.pkl loaded: shape = (1000, 13)\n",
      "batch_420.pkl loaded: shape = (1000, 13)\n",
      "batch_421.pkl loaded: shape = (1000, 13)\n",
      "batch_422.pkl loaded: shape = (1000, 13)\n",
      "batch_423.pkl loaded: shape = (1000, 13)\n",
      "batch_424.pkl loaded: shape = (1000, 13)\n",
      "batch_425.pkl loaded: shape = (1000, 13)\n",
      "batch_426.pkl loaded: shape = (1000, 13)\n",
      "batch_427.pkl loaded: shape = (1000, 13)\n",
      "batch_428.pkl loaded: shape = (1000, 13)\n",
      "batch_429.pkl loaded: shape = (1000, 13)\n",
      "batch_43.pkl loaded: shape = (1000, 13)\n",
      "batch_430.pkl loaded: shape = (1000, 13)\n",
      "batch_431.pkl loaded: shape = (1000, 13)\n",
      "batch_432.pkl loaded: shape = (1000, 13)\n",
      "batch_433.pkl loaded: shape = (1000, 13)\n",
      "batch_434.pkl loaded: shape = (1000, 13)\n",
      "batch_435.pkl loaded: shape = (1000, 13)\n",
      "batch_436.pkl loaded: shape = (1000, 13)\n",
      "batch_437.pkl loaded: shape = (1000, 13)\n",
      "batch_438.pkl loaded: shape = (1000, 13)\n",
      "batch_439.pkl loaded: shape = (1000, 13)\n",
      "batch_44.pkl loaded: shape = (1000, 13)\n",
      "batch_440.pkl loaded: shape = (1000, 13)\n",
      "batch_441.pkl loaded: shape = (1000, 13)\n",
      "batch_442.pkl loaded: shape = (1000, 13)\n",
      "batch_443.pkl loaded: shape = (1000, 13)\n",
      "batch_444.pkl loaded: shape = (1000, 13)\n",
      "batch_445.pkl loaded: shape = (1000, 13)\n",
      "batch_446.pkl loaded: shape = (1000, 13)\n",
      "batch_447.pkl loaded: shape = (1000, 13)\n",
      "batch_448.pkl loaded: shape = (1000, 13)\n",
      "batch_449.pkl loaded: shape = (1000, 13)\n",
      "batch_45.pkl loaded: shape = (1000, 13)\n",
      "batch_450.pkl loaded: shape = (1000, 13)\n",
      "batch_451.pkl loaded: shape = (1000, 13)\n",
      "batch_452.pkl loaded: shape = (1000, 13)\n",
      "batch_453.pkl loaded: shape = (1000, 13)\n",
      "batch_454.pkl loaded: shape = (1000, 13)\n",
      "batch_455.pkl loaded: shape = (1000, 13)\n",
      "batch_456.pkl loaded: shape = (1000, 13)\n",
      "batch_457.pkl loaded: shape = (1000, 13)\n",
      "batch_458.pkl loaded: shape = (1000, 13)\n",
      "batch_459.pkl loaded: shape = (1000, 13)\n",
      "batch_46.pkl loaded: shape = (1000, 13)\n",
      "batch_460.pkl loaded: shape = (1000, 13)\n",
      "batch_461.pkl loaded: shape = (1000, 13)\n",
      "batch_462.pkl loaded: shape = (1000, 13)\n",
      "batch_463.pkl loaded: shape = (1000, 13)\n",
      "batch_464.pkl loaded: shape = (1000, 13)\n",
      "batch_465.pkl loaded: shape = (1000, 13)\n",
      "batch_466.pkl loaded: shape = (1000, 13)\n",
      "batch_467.pkl loaded: shape = (1000, 13)\n",
      "batch_468.pkl loaded: shape = (1000, 13)\n",
      "batch_469.pkl loaded: shape = (1000, 13)\n",
      "batch_47.pkl loaded: shape = (1000, 13)\n",
      "batch_470.pkl loaded: shape = (1000, 13)\n",
      "batch_471.pkl loaded: shape = (1000, 13)\n",
      "batch_472.pkl loaded: shape = (1000, 13)\n",
      "batch_473.pkl loaded: shape = (1000, 13)\n",
      "batch_474.pkl loaded: shape = (1000, 13)\n",
      "batch_475.pkl loaded: shape = (1000, 13)\n",
      "batch_476.pkl loaded: shape = (1000, 13)\n",
      "batch_477.pkl loaded: shape = (1000, 13)\n",
      "batch_478.pkl loaded: shape = (1000, 13)\n",
      "batch_479.pkl loaded: shape = (1000, 13)\n",
      "batch_48.pkl loaded: shape = (1000, 13)\n",
      "batch_480.pkl loaded: shape = (1000, 13)\n",
      "batch_481.pkl loaded: shape = (1000, 13)\n",
      "batch_482.pkl loaded: shape = (1000, 13)\n",
      "batch_483.pkl loaded: shape = (1000, 13)\n",
      "batch_484.pkl loaded: shape = (1000, 13)\n",
      "batch_485.pkl loaded: shape = (1000, 13)\n",
      "batch_486.pkl loaded: shape = (1000, 13)\n",
      "batch_487.pkl loaded: shape = (1000, 13)\n",
      "batch_488.pkl loaded: shape = (1000, 13)\n",
      "batch_489.pkl loaded: shape = (1000, 13)\n",
      "batch_49.pkl loaded: shape = (1000, 13)\n",
      "batch_490.pkl loaded: shape = (1000, 13)\n",
      "batch_491.pkl loaded: shape = (1000, 13)\n",
      "batch_492.pkl loaded: shape = (1000, 13)\n",
      "batch_493.pkl loaded: shape = (1000, 13)\n",
      "batch_494.pkl loaded: shape = (1000, 13)\n",
      "batch_495.pkl loaded: shape = (1000, 13)\n",
      "batch_496.pkl loaded: shape = (1000, 13)\n",
      "batch_497.pkl loaded: shape = (1000, 13)\n",
      "batch_498.pkl loaded: shape = (1000, 13)\n",
      "batch_499.pkl loaded: shape = (1000, 13)\n",
      "batch_5.pkl loaded: shape = (1000, 13)\n",
      "batch_50.pkl loaded: shape = (1000, 13)\n",
      "batch_500.pkl loaded: shape = (1000, 13)\n",
      "batch_501.pkl loaded: shape = (1000, 13)\n",
      "batch_502.pkl loaded: shape = (1000, 13)\n",
      "batch_503.pkl loaded: shape = (1000, 13)\n",
      "batch_504.pkl loaded: shape = (1000, 13)\n",
      "batch_505.pkl loaded: shape = (1000, 13)\n",
      "batch_506.pkl loaded: shape = (1000, 13)\n",
      "batch_507.pkl loaded: shape = (1000, 13)\n",
      "batch_508.pkl loaded: shape = (1000, 13)\n",
      "batch_509.pkl loaded: shape = (1000, 13)\n",
      "batch_51.pkl loaded: shape = (1000, 13)\n",
      "batch_510.pkl loaded: shape = (1000, 13)\n",
      "batch_511.pkl loaded: shape = (1000, 13)\n",
      "batch_512.pkl loaded: shape = (1000, 13)\n",
      "batch_513.pkl loaded: shape = (1000, 13)\n",
      "batch_514.pkl loaded: shape = (1000, 13)\n",
      "batch_515.pkl loaded: shape = (1000, 13)\n",
      "batch_516.pkl loaded: shape = (1000, 13)\n",
      "batch_517.pkl loaded: shape = (1000, 13)\n",
      "batch_518.pkl loaded: shape = (1000, 13)\n",
      "batch_519.pkl loaded: shape = (1000, 13)\n",
      "batch_52.pkl loaded: shape = (1000, 13)\n",
      "batch_520.pkl loaded: shape = (1000, 13)\n",
      "batch_521.pkl loaded: shape = (1000, 13)\n",
      "batch_522.pkl loaded: shape = (1000, 13)\n",
      "batch_523.pkl loaded: shape = (1000, 13)\n",
      "batch_524.pkl loaded: shape = (1000, 13)\n",
      "batch_525.pkl loaded: shape = (1000, 13)\n",
      "batch_526.pkl loaded: shape = (1000, 13)\n",
      "batch_527.pkl loaded: shape = (1000, 13)\n",
      "batch_528.pkl loaded: shape = (1000, 13)\n",
      "batch_529.pkl loaded: shape = (1000, 13)\n",
      "batch_53.pkl loaded: shape = (1000, 13)\n",
      "batch_530.pkl loaded: shape = (1000, 13)\n",
      "batch_531.pkl loaded: shape = (1000, 13)\n",
      "batch_532.pkl loaded: shape = (1000, 13)\n",
      "batch_533.pkl loaded: shape = (1000, 13)\n",
      "batch_534.pkl loaded: shape = (1000, 13)\n",
      "batch_535.pkl loaded: shape = (1000, 13)\n",
      "batch_536.pkl loaded: shape = (1000, 13)\n",
      "batch_537.pkl loaded: shape = (1000, 13)\n",
      "batch_538.pkl loaded: shape = (1000, 13)\n",
      "batch_539.pkl loaded: shape = (1000, 13)\n",
      "batch_54.pkl loaded: shape = (1000, 13)\n",
      "batch_540.pkl loaded: shape = (1000, 13)\n",
      "batch_541.pkl loaded: shape = (1000, 13)\n",
      "batch_542.pkl loaded: shape = (1000, 13)\n",
      "batch_543.pkl loaded: shape = (1000, 13)\n",
      "batch_544.pkl loaded: shape = (1000, 13)\n",
      "batch_545.pkl loaded: shape = (1000, 13)\n",
      "batch_546.pkl loaded: shape = (1000, 13)\n",
      "batch_547.pkl loaded: shape = (1000, 13)\n",
      "batch_548.pkl loaded: shape = (1000, 13)\n",
      "batch_549.pkl loaded: shape = (1000, 13)\n",
      "batch_55.pkl loaded: shape = (1000, 13)\n",
      "batch_550.pkl loaded: shape = (1000, 13)\n",
      "batch_551.pkl loaded: shape = (1000, 13)\n",
      "batch_552.pkl loaded: shape = (1000, 13)\n",
      "batch_553.pkl loaded: shape = (1000, 13)\n",
      "batch_554.pkl loaded: shape = (1000, 13)\n",
      "batch_555.pkl loaded: shape = (1000, 13)\n",
      "batch_556.pkl loaded: shape = (1000, 13)\n",
      "batch_557.pkl loaded: shape = (1000, 13)\n",
      "batch_558.pkl loaded: shape = (1000, 13)\n",
      "batch_559.pkl loaded: shape = (1000, 13)\n",
      "batch_56.pkl loaded: shape = (1000, 13)\n",
      "batch_560.pkl loaded: shape = (1000, 13)\n",
      "batch_561.pkl loaded: shape = (1000, 13)\n",
      "batch_562.pkl loaded: shape = (1000, 13)\n",
      "batch_563.pkl loaded: shape = (1000, 13)\n",
      "batch_564.pkl loaded: shape = (1000, 13)\n",
      "batch_565.pkl loaded: shape = (1000, 13)\n",
      "batch_566.pkl loaded: shape = (1000, 13)\n",
      "batch_567.pkl loaded: shape = (1000, 13)\n",
      "batch_568.pkl loaded: shape = (1000, 13)\n",
      "batch_569.pkl loaded: shape = (1000, 13)\n",
      "batch_57.pkl loaded: shape = (1000, 13)\n",
      "batch_570.pkl loaded: shape = (1000, 13)\n",
      "batch_571.pkl loaded: shape = (1000, 13)\n",
      "batch_572.pkl loaded: shape = (1000, 13)\n",
      "batch_573.pkl loaded: shape = (1000, 13)\n",
      "batch_574.pkl loaded: shape = (1000, 13)\n",
      "batch_575.pkl loaded: shape = (1000, 13)\n",
      "batch_576.pkl loaded: shape = (1000, 13)\n",
      "batch_577.pkl loaded: shape = (1000, 13)\n",
      "batch_578.pkl loaded: shape = (1000, 13)\n",
      "batch_579.pkl loaded: shape = (1000, 13)\n",
      "batch_58.pkl loaded: shape = (1000, 13)\n",
      "batch_580.pkl loaded: shape = (1000, 13)\n",
      "batch_581.pkl loaded: shape = (1000, 13)\n",
      "batch_582.pkl loaded: shape = (1000, 13)\n",
      "batch_583.pkl loaded: shape = (1000, 13)\n",
      "batch_584.pkl loaded: shape = (1000, 13)\n",
      "batch_585.pkl loaded: shape = (1000, 13)\n",
      "batch_586.pkl loaded: shape = (1000, 13)\n",
      "batch_587.pkl loaded: shape = (1000, 13)\n",
      "batch_588.pkl loaded: shape = (1000, 13)\n",
      "batch_589.pkl loaded: shape = (1000, 13)\n",
      "batch_59.pkl loaded: shape = (1000, 13)\n",
      "batch_590.pkl loaded: shape = (1000, 13)\n",
      "batch_591.pkl loaded: shape = (1000, 13)\n",
      "batch_592.pkl loaded: shape = (1000, 13)\n",
      "batch_593.pkl loaded: shape = (1000, 13)\n",
      "batch_594.pkl loaded: shape = (1000, 13)\n",
      "batch_595.pkl loaded: shape = (1000, 13)\n",
      "batch_596.pkl loaded: shape = (1000, 13)\n",
      "batch_597.pkl loaded: shape = (1000, 13)\n",
      "batch_598.pkl loaded: shape = (1000, 13)\n",
      "batch_599.pkl loaded: shape = (1000, 13)\n",
      "batch_6.pkl loaded: shape = (1000, 13)\n",
      "batch_60.pkl loaded: shape = (1000, 13)\n",
      "batch_600.pkl loaded: shape = (1000, 13)\n",
      "batch_601.pkl loaded: shape = (1000, 13)\n",
      "batch_602.pkl loaded: shape = (1000, 13)\n",
      "batch_603.pkl loaded: shape = (1000, 13)\n",
      "batch_604.pkl loaded: shape = (1000, 13)\n",
      "batch_605.pkl loaded: shape = (1000, 13)\n",
      "batch_606.pkl loaded: shape = (1000, 13)\n",
      "batch_607.pkl loaded: shape = (1000, 13)\n",
      "batch_608.pkl loaded: shape = (1000, 13)\n",
      "batch_609.pkl loaded: shape = (1000, 13)\n",
      "batch_61.pkl loaded: shape = (1000, 13)\n",
      "batch_610.pkl loaded: shape = (1000, 13)\n",
      "batch_611.pkl loaded: shape = (1000, 13)\n",
      "batch_612.pkl loaded: shape = (1000, 13)\n",
      "batch_613.pkl loaded: shape = (1000, 13)\n",
      "batch_614.pkl loaded: shape = (1000, 13)\n",
      "batch_615.pkl loaded: shape = (1000, 13)\n",
      "batch_616.pkl loaded: shape = (1000, 13)\n",
      "batch_617.pkl loaded: shape = (1000, 13)\n",
      "batch_618.pkl loaded: shape = (1000, 13)\n",
      "batch_619.pkl loaded: shape = (1000, 13)\n",
      "batch_62.pkl loaded: shape = (1000, 13)\n",
      "batch_620.pkl loaded: shape = (1000, 13)\n",
      "batch_621.pkl loaded: shape = (1000, 13)\n",
      "batch_622.pkl loaded: shape = (1000, 13)\n",
      "batch_623.pkl loaded: shape = (1000, 13)\n",
      "batch_624.pkl loaded: shape = (1000, 13)\n",
      "batch_625.pkl loaded: shape = (1000, 13)\n",
      "batch_626.pkl loaded: shape = (1000, 13)\n",
      "batch_627.pkl loaded: shape = (1000, 13)\n",
      "batch_628.pkl loaded: shape = (1000, 13)\n",
      "batch_629.pkl loaded: shape = (1000, 13)\n",
      "batch_63.pkl loaded: shape = (1000, 13)\n",
      "batch_630.pkl loaded: shape = (1000, 13)\n",
      "batch_631.pkl loaded: shape = (1000, 13)\n",
      "batch_632.pkl loaded: shape = (1000, 13)\n",
      "batch_633.pkl loaded: shape = (1000, 13)\n",
      "batch_634.pkl loaded: shape = (1000, 13)\n",
      "batch_635.pkl loaded: shape = (1000, 13)\n",
      "batch_636.pkl loaded: shape = (1000, 13)\n",
      "batch_637.pkl loaded: shape = (1000, 13)\n",
      "batch_638.pkl loaded: shape = (1000, 13)\n",
      "batch_639.pkl loaded: shape = (1000, 13)\n",
      "batch_64.pkl loaded: shape = (1000, 13)\n",
      "batch_640.pkl loaded: shape = (1000, 13)\n",
      "batch_641.pkl loaded: shape = (1000, 13)\n",
      "batch_642.pkl loaded: shape = (1000, 13)\n",
      "batch_643.pkl loaded: shape = (1000, 13)\n",
      "batch_644.pkl loaded: shape = (1000, 13)\n",
      "batch_645.pkl loaded: shape = (1000, 13)\n",
      "batch_646.pkl loaded: shape = (1000, 13)\n",
      "batch_647.pkl loaded: shape = (1000, 13)\n",
      "batch_648.pkl loaded: shape = (1000, 13)\n",
      "batch_649.pkl loaded: shape = (1000, 13)\n",
      "batch_65.pkl loaded: shape = (1000, 13)\n",
      "batch_650.pkl loaded: shape = (1000, 13)\n",
      "batch_651.pkl loaded: shape = (1000, 13)\n",
      "batch_652.pkl loaded: shape = (1000, 13)\n",
      "batch_653.pkl loaded: shape = (1000, 13)\n",
      "batch_654.pkl loaded: shape = (1000, 13)\n",
      "batch_655.pkl loaded: shape = (1000, 13)\n",
      "batch_656.pkl loaded: shape = (1000, 13)\n",
      "batch_657.pkl loaded: shape = (1000, 13)\n",
      "batch_658.pkl loaded: shape = (1000, 13)\n",
      "batch_659.pkl loaded: shape = (1000, 13)\n",
      "batch_66.pkl loaded: shape = (1000, 13)\n",
      "batch_660.pkl loaded: shape = (1000, 13)\n",
      "batch_661.pkl loaded: shape = (1000, 13)\n",
      "batch_662.pkl loaded: shape = (1000, 13)\n",
      "batch_663.pkl loaded: shape = (1000, 13)\n",
      "batch_664.pkl loaded: shape = (1000, 13)\n",
      "batch_665.pkl loaded: shape = (1000, 13)\n",
      "batch_666.pkl loaded: shape = (1000, 13)\n",
      "batch_667.pkl loaded: shape = (1000, 13)\n",
      "batch_668.pkl loaded: shape = (1000, 13)\n",
      "batch_669.pkl loaded: shape = (1000, 13)\n",
      "batch_67.pkl loaded: shape = (1000, 13)\n",
      "batch_670.pkl loaded: shape = (1000, 13)\n",
      "batch_671.pkl loaded: shape = (1000, 13)\n",
      "batch_672.pkl loaded: shape = (1000, 13)\n",
      "batch_673.pkl loaded: shape = (1000, 13)\n",
      "batch_674.pkl loaded: shape = (1000, 13)\n",
      "batch_675.pkl loaded: shape = (1000, 13)\n",
      "batch_676.pkl loaded: shape = (1000, 13)\n",
      "batch_677.pkl loaded: shape = (1000, 13)\n",
      "batch_678.pkl loaded: shape = (1000, 13)\n",
      "batch_679.pkl loaded: shape = (1000, 13)\n",
      "batch_68.pkl loaded: shape = (1000, 13)\n",
      "batch_680.pkl loaded: shape = (1000, 13)\n",
      "batch_681.pkl loaded: shape = (1000, 13)\n",
      "batch_682.pkl loaded: shape = (1000, 13)\n",
      "batch_683.pkl loaded: shape = (1000, 13)\n",
      "batch_684.pkl loaded: shape = (1000, 13)\n",
      "batch_685.pkl loaded: shape = (1000, 13)\n",
      "batch_686.pkl loaded: shape = (1000, 13)\n",
      "batch_687.pkl loaded: shape = (1000, 13)\n",
      "batch_688.pkl loaded: shape = (1000, 13)\n",
      "batch_689.pkl loaded: shape = (1000, 13)\n",
      "batch_69.pkl loaded: shape = (1000, 13)\n",
      "batch_690.pkl loaded: shape = (1000, 13)\n",
      "batch_691.pkl loaded: shape = (1000, 13)\n",
      "batch_692.pkl loaded: shape = (1000, 13)\n",
      "batch_693.pkl loaded: shape = (1000, 13)\n",
      "batch_694.pkl loaded: shape = (1000, 13)\n",
      "batch_695.pkl loaded: shape = (1000, 13)\n",
      "batch_696.pkl loaded: shape = (1000, 13)\n",
      "batch_697.pkl loaded: shape = (1000, 13)\n",
      "batch_698.pkl loaded: shape = (1000, 13)\n",
      "batch_699.pkl loaded: shape = (1000, 13)\n",
      "batch_7.pkl loaded: shape = (1000, 13)\n",
      "batch_70.pkl loaded: shape = (1000, 13)\n",
      "batch_700.pkl loaded: shape = (1000, 13)\n",
      "batch_701.pkl loaded: shape = (1000, 13)\n",
      "batch_702.pkl loaded: shape = (1000, 13)\n",
      "batch_703.pkl loaded: shape = (1000, 13)\n",
      "batch_704.pkl loaded: shape = (1000, 13)\n",
      "batch_705.pkl loaded: shape = (1000, 13)\n",
      "batch_706.pkl loaded: shape = (1000, 13)\n",
      "batch_707.pkl loaded: shape = (1000, 13)\n",
      "batch_708.pkl loaded: shape = (1000, 13)\n",
      "batch_709.pkl loaded: shape = (1000, 13)\n",
      "batch_71.pkl loaded: shape = (1000, 13)\n",
      "batch_710.pkl loaded: shape = (1000, 13)\n",
      "batch_711.pkl loaded: shape = (1000, 13)\n",
      "batch_712.pkl loaded: shape = (1000, 13)\n",
      "batch_713.pkl loaded: shape = (1000, 13)\n",
      "batch_714.pkl loaded: shape = (1000, 13)\n",
      "batch_715.pkl loaded: shape = (1000, 13)\n",
      "batch_716.pkl loaded: shape = (1000, 13)\n",
      "batch_717.pkl loaded: shape = (1000, 13)\n",
      "batch_718.pkl loaded: shape = (1000, 13)\n",
      "batch_719.pkl loaded: shape = (1000, 13)\n",
      "batch_72.pkl loaded: shape = (1000, 13)\n",
      "batch_720.pkl loaded: shape = (1000, 13)\n",
      "batch_721.pkl loaded: shape = (1000, 13)\n",
      "batch_722.pkl loaded: shape = (1000, 13)\n",
      "batch_723.pkl loaded: shape = (1000, 13)\n",
      "batch_724.pkl loaded: shape = (1000, 13)\n",
      "batch_725.pkl loaded: shape = (1000, 13)\n",
      "batch_726.pkl loaded: shape = (1000, 13)\n",
      "batch_727.pkl loaded: shape = (1000, 13)\n",
      "batch_728.pkl loaded: shape = (1000, 13)\n",
      "batch_729.pkl loaded: shape = (1000, 13)\n",
      "batch_73.pkl loaded: shape = (1000, 13)\n",
      "batch_730.pkl loaded: shape = (1000, 13)\n",
      "batch_731.pkl loaded: shape = (1000, 13)\n",
      "batch_732.pkl loaded: shape = (1000, 13)\n",
      "batch_733.pkl loaded: shape = (1000, 13)\n",
      "batch_734.pkl loaded: shape = (1000, 13)\n",
      "batch_735.pkl loaded: shape = (1000, 13)\n",
      "batch_736.pkl loaded: shape = (1000, 13)\n",
      "batch_737.pkl loaded: shape = (1000, 13)\n",
      "batch_738.pkl loaded: shape = (1000, 13)\n",
      "batch_739.pkl loaded: shape = (1000, 13)\n",
      "batch_74.pkl loaded: shape = (1000, 13)\n",
      "batch_740.pkl loaded: shape = (1000, 13)\n",
      "batch_741.pkl loaded: shape = (1000, 13)\n",
      "batch_742.pkl loaded: shape = (1000, 13)\n",
      "batch_743.pkl loaded: shape = (1000, 13)\n",
      "batch_744.pkl loaded: shape = (1000, 13)\n",
      "batch_745.pkl loaded: shape = (1000, 13)\n",
      "batch_746.pkl loaded: shape = (1000, 13)\n",
      "batch_747.pkl loaded: shape = (1000, 13)\n",
      "batch_748.pkl loaded: shape = (1000, 13)\n",
      "batch_749.pkl loaded: shape = (1000, 13)\n",
      "batch_75.pkl loaded: shape = (1000, 13)\n",
      "batch_750.pkl loaded: shape = (1000, 13)\n",
      "batch_751.pkl loaded: shape = (1000, 13)\n",
      "batch_752.pkl loaded: shape = (1000, 13)\n",
      "batch_753.pkl loaded: shape = (1000, 13)\n",
      "batch_754.pkl loaded: shape = (1000, 13)\n",
      "batch_755.pkl loaded: shape = (1000, 13)\n",
      "batch_756.pkl loaded: shape = (1000, 13)\n",
      "batch_757.pkl loaded: shape = (1000, 13)\n",
      "batch_758.pkl loaded: shape = (1000, 13)\n",
      "batch_759.pkl loaded: shape = (1000, 13)\n",
      "batch_76.pkl loaded: shape = (1000, 13)\n",
      "batch_760.pkl loaded: shape = (1000, 13)\n",
      "batch_761.pkl loaded: shape = (1000, 13)\n",
      "batch_762.pkl loaded: shape = (1000, 13)\n",
      "batch_763.pkl loaded: shape = (1000, 13)\n",
      "batch_764.pkl loaded: shape = (1000, 13)\n",
      "batch_765.pkl loaded: shape = (1000, 13)\n",
      "batch_766.pkl loaded: shape = (1000, 13)\n",
      "batch_767.pkl loaded: shape = (1000, 13)\n",
      "batch_768.pkl loaded: shape = (1000, 13)\n",
      "batch_769.pkl loaded: shape = (1000, 13)\n",
      "batch_77.pkl loaded: shape = (1000, 13)\n",
      "batch_770.pkl loaded: shape = (1000, 13)\n",
      "batch_771.pkl loaded: shape = (1000, 13)\n",
      "batch_772.pkl loaded: shape = (1000, 13)\n",
      "batch_773.pkl loaded: shape = (1000, 13)\n",
      "batch_774.pkl loaded: shape = (1000, 13)\n",
      "batch_775.pkl loaded: shape = (1000, 13)\n",
      "batch_776.pkl loaded: shape = (1000, 13)\n",
      "batch_777.pkl loaded: shape = (1000, 13)\n",
      "batch_778.pkl loaded: shape = (1000, 13)\n",
      "batch_779.pkl loaded: shape = (1000, 13)\n",
      "batch_78.pkl loaded: shape = (1000, 13)\n",
      "batch_780.pkl loaded: shape = (1000, 13)\n",
      "batch_781.pkl loaded: shape = (1000, 13)\n",
      "batch_782.pkl loaded: shape = (1000, 13)\n",
      "batch_783.pkl loaded: shape = (1000, 13)\n",
      "batch_784.pkl loaded: shape = (1000, 13)\n",
      "batch_785.pkl loaded: shape = (1000, 13)\n",
      "batch_786.pkl loaded: shape = (1000, 13)\n",
      "batch_787.pkl loaded: shape = (1000, 13)\n",
      "batch_788.pkl loaded: shape = (1000, 13)\n",
      "batch_789.pkl loaded: shape = (1000, 13)\n",
      "batch_79.pkl loaded: shape = (1000, 13)\n",
      "batch_790.pkl loaded: shape = (1000, 13)\n",
      "batch_791.pkl loaded: shape = (1000, 13)\n",
      "batch_792.pkl loaded: shape = (1000, 13)\n",
      "batch_793.pkl loaded: shape = (1000, 13)\n",
      "batch_794.pkl loaded: shape = (1000, 13)\n",
      "batch_795.pkl loaded: shape = (1000, 13)\n",
      "batch_796.pkl loaded: shape = (1000, 13)\n",
      "batch_797.pkl loaded: shape = (1000, 13)\n",
      "batch_798.pkl loaded: shape = (1000, 13)\n",
      "batch_799.pkl loaded: shape = (1000, 13)\n",
      "batch_8.pkl loaded: shape = (1000, 13)\n",
      "batch_80.pkl loaded: shape = (1000, 13)\n",
      "batch_800.pkl loaded: shape = (1000, 13)\n",
      "batch_801.pkl loaded: shape = (1000, 13)\n",
      "batch_802.pkl loaded: shape = (1000, 13)\n",
      "batch_803.pkl loaded: shape = (1000, 13)\n",
      "batch_804.pkl loaded: shape = (1000, 13)\n",
      "batch_805.pkl loaded: shape = (1000, 13)\n",
      "batch_806.pkl loaded: shape = (1000, 13)\n",
      "batch_807.pkl loaded: shape = (1000, 13)\n",
      "batch_808.pkl loaded: shape = (1000, 13)\n",
      "batch_809.pkl loaded: shape = (1000, 13)\n",
      "batch_81.pkl loaded: shape = (1000, 13)\n",
      "batch_810.pkl loaded: shape = (1000, 13)\n",
      "batch_811.pkl loaded: shape = (1000, 13)\n",
      "batch_812.pkl loaded: shape = (1000, 13)\n",
      "batch_813.pkl loaded: shape = (1000, 13)\n",
      "batch_814.pkl loaded: shape = (1000, 13)\n",
      "batch_815.pkl loaded: shape = (1000, 13)\n",
      "batch_816.pkl loaded: shape = (1000, 13)\n",
      "batch_817.pkl loaded: shape = (1000, 13)\n",
      "batch_818.pkl loaded: shape = (1000, 13)\n",
      "batch_819.pkl loaded: shape = (1000, 13)\n",
      "batch_82.pkl loaded: shape = (1000, 13)\n",
      "batch_820.pkl loaded: shape = (1000, 13)\n",
      "batch_821.pkl loaded: shape = (1000, 13)\n",
      "batch_822.pkl loaded: shape = (1000, 13)\n",
      "batch_823.pkl loaded: shape = (1000, 13)\n",
      "batch_824.pkl loaded: shape = (1000, 13)\n",
      "batch_825.pkl loaded: shape = (1000, 13)\n",
      "batch_826.pkl loaded: shape = (1000, 13)\n",
      "batch_827.pkl loaded: shape = (1000, 13)\n",
      "batch_828.pkl loaded: shape = (1000, 13)\n",
      "batch_829.pkl loaded: shape = (1000, 13)\n",
      "batch_83.pkl loaded: shape = (1000, 13)\n",
      "batch_830.pkl loaded: shape = (1000, 13)\n",
      "batch_831.pkl loaded: shape = (1000, 13)\n",
      "batch_832.pkl loaded: shape = (1000, 13)\n",
      "batch_833.pkl loaded: shape = (1000, 13)\n",
      "batch_834.pkl loaded: shape = (1000, 13)\n",
      "batch_835.pkl loaded: shape = (1000, 13)\n",
      "batch_836.pkl loaded: shape = (1000, 13)\n",
      "batch_837.pkl loaded: shape = (1000, 13)\n",
      "batch_838.pkl loaded: shape = (1000, 13)\n",
      "batch_839.pkl loaded: shape = (1000, 13)\n",
      "batch_84.pkl loaded: shape = (1000, 13)\n",
      "batch_840.pkl loaded: shape = (1000, 13)\n",
      "batch_841.pkl loaded: shape = (1000, 13)\n",
      "batch_842.pkl loaded: shape = (1000, 13)\n",
      "batch_843.pkl loaded: shape = (1000, 13)\n",
      "batch_844.pkl loaded: shape = (1000, 13)\n",
      "batch_845.pkl loaded: shape = (1000, 13)\n",
      "batch_846.pkl loaded: shape = (1000, 13)\n",
      "batch_847.pkl loaded: shape = (1000, 13)\n",
      "batch_848.pkl loaded: shape = (1000, 13)\n",
      "batch_849.pkl loaded: shape = (1000, 13)\n",
      "batch_85.pkl loaded: shape = (1000, 13)\n",
      "batch_850.pkl loaded: shape = (1000, 13)\n",
      "batch_851.pkl loaded: shape = (1000, 13)\n",
      "batch_852.pkl loaded: shape = (1000, 13)\n",
      "batch_853.pkl loaded: shape = (1000, 13)\n",
      "batch_854.pkl loaded: shape = (1000, 13)\n",
      "batch_855.pkl loaded: shape = (1000, 13)\n",
      "batch_856.pkl loaded: shape = (1000, 13)\n",
      "batch_857.pkl loaded: shape = (1000, 13)\n",
      "batch_858.pkl loaded: shape = (1000, 13)\n",
      "batch_859.pkl loaded: shape = (1000, 13)\n",
      "batch_86.pkl loaded: shape = (1000, 13)\n",
      "batch_860.pkl loaded: shape = (1000, 13)\n",
      "batch_861.pkl loaded: shape = (1000, 13)\n",
      "batch_862.pkl loaded: shape = (1000, 13)\n",
      "batch_863.pkl loaded: shape = (1000, 13)\n",
      "batch_864.pkl loaded: shape = (1000, 13)\n",
      "batch_865.pkl loaded: shape = (1000, 13)\n",
      "batch_866.pkl loaded: shape = (1000, 13)\n",
      "batch_867.pkl loaded: shape = (1000, 13)\n",
      "batch_868.pkl loaded: shape = (1000, 13)\n",
      "batch_869.pkl loaded: shape = (1000, 13)\n",
      "batch_87.pkl loaded: shape = (1000, 13)\n",
      "batch_870.pkl loaded: shape = (1000, 13)\n",
      "batch_871.pkl loaded: shape = (1000, 13)\n",
      "batch_872.pkl loaded: shape = (1000, 13)\n",
      "batch_873.pkl loaded: shape = (1000, 13)\n",
      "batch_874.pkl loaded: shape = (1000, 13)\n",
      "batch_875.pkl loaded: shape = (1000, 13)\n",
      "batch_876.pkl loaded: shape = (1000, 13)\n",
      "batch_877.pkl loaded: shape = (1000, 13)\n",
      "batch_878.pkl loaded: shape = (1000, 13)\n",
      "batch_879.pkl loaded: shape = (1000, 13)\n",
      "batch_88.pkl loaded: shape = (1000, 13)\n",
      "batch_880.pkl loaded: shape = (1000, 13)\n",
      "batch_881.pkl loaded: shape = (1000, 13)\n",
      "batch_882.pkl loaded: shape = (1000, 13)\n",
      "batch_883.pkl loaded: shape = (1000, 13)\n",
      "batch_884.pkl loaded: shape = (1000, 13)\n",
      "batch_885.pkl loaded: shape = (1000, 13)\n",
      "batch_886.pkl loaded: shape = (1000, 13)\n",
      "batch_887.pkl loaded: shape = (1000, 13)\n",
      "batch_888.pkl loaded: shape = (1000, 13)\n",
      "batch_889.pkl loaded: shape = (1000, 13)\n",
      "batch_89.pkl loaded: shape = (1000, 13)\n",
      "batch_890.pkl loaded: shape = (1000, 13)\n",
      "batch_891.pkl loaded: shape = (1000, 13)\n",
      "batch_892.pkl loaded: shape = (1000, 13)\n",
      "batch_893.pkl loaded: shape = (1000, 13)\n",
      "batch_894.pkl loaded: shape = (1000, 13)\n",
      "batch_895.pkl loaded: shape = (1000, 13)\n",
      "batch_896.pkl loaded: shape = (1000, 13)\n",
      "batch_897.pkl loaded: shape = (1000, 13)\n",
      "batch_898.pkl loaded: shape = (1000, 13)\n",
      "batch_899.pkl loaded: shape = (1000, 13)\n",
      "batch_9.pkl loaded: shape = (1000, 13)\n",
      "batch_90.pkl loaded: shape = (1000, 13)\n",
      "batch_900.pkl loaded: shape = (1000, 13)\n",
      "batch_901.pkl loaded: shape = (1000, 13)\n",
      "batch_902.pkl loaded: shape = (1000, 13)\n",
      "batch_903.pkl loaded: shape = (1000, 13)\n",
      "batch_904.pkl loaded: shape = (1000, 13)\n",
      "batch_905.pkl loaded: shape = (1000, 13)\n",
      "batch_906.pkl loaded: shape = (1000, 13)\n",
      "batch_907.pkl loaded: shape = (1000, 13)\n",
      "batch_908.pkl loaded: shape = (1000, 13)\n",
      "batch_909.pkl loaded: shape = (1000, 13)\n",
      "batch_91.pkl loaded: shape = (1000, 13)\n",
      "batch_910.pkl loaded: shape = (1000, 13)\n",
      "batch_911.pkl loaded: shape = (1000, 13)\n",
      "batch_912.pkl loaded: shape = (1000, 13)\n",
      "batch_913.pkl loaded: shape = (1000, 13)\n",
      "batch_914.pkl loaded: shape = (1000, 13)\n",
      "batch_915.pkl loaded: shape = (1000, 13)\n",
      "batch_916.pkl loaded: shape = (1000, 13)\n",
      "batch_917.pkl loaded: shape = (1000, 13)\n",
      "batch_918.pkl loaded: shape = (1000, 13)\n",
      "batch_919.pkl loaded: shape = (1000, 13)\n",
      "batch_92.pkl loaded: shape = (1000, 13)\n",
      "batch_920.pkl loaded: shape = (1000, 13)\n",
      "batch_921.pkl loaded: shape = (1000, 13)\n",
      "batch_922.pkl loaded: shape = (1000, 13)\n",
      "batch_923.pkl loaded: shape = (1000, 13)\n",
      "batch_924.pkl loaded: shape = (1000, 13)\n",
      "batch_925.pkl loaded: shape = (1000, 13)\n",
      "batch_926.pkl loaded: shape = (1000, 13)\n",
      "batch_927.pkl loaded: shape = (1000, 13)\n",
      "batch_928.pkl loaded: shape = (1000, 13)\n",
      "batch_929.pkl loaded: shape = (1000, 13)\n",
      "batch_93.pkl loaded: shape = (1000, 13)\n",
      "batch_930.pkl loaded: shape = (1000, 13)\n",
      "batch_931.pkl loaded: shape = (1000, 13)\n",
      "batch_932.pkl loaded: shape = (1000, 13)\n",
      "batch_933.pkl loaded: shape = (1000, 13)\n",
      "batch_934.pkl loaded: shape = (1000, 13)\n",
      "batch_935.pkl loaded: shape = (1000, 13)\n",
      "batch_936.pkl loaded: shape = (1000, 13)\n",
      "batch_937.pkl loaded: shape = (1000, 13)\n",
      "batch_938.pkl loaded: shape = (1000, 13)\n",
      "batch_939.pkl loaded: shape = (1000, 13)\n",
      "batch_94.pkl loaded: shape = (1000, 13)\n",
      "batch_940.pkl loaded: shape = (1000, 13)\n",
      "batch_941.pkl loaded: shape = (1000, 13)\n",
      "batch_942.pkl loaded: shape = (1000, 13)\n",
      "batch_943.pkl loaded: shape = (1000, 13)\n",
      "batch_944.pkl loaded: shape = (1000, 13)\n",
      "batch_945.pkl loaded: shape = (1000, 13)\n",
      "batch_946.pkl loaded: shape = (1000, 13)\n",
      "batch_947.pkl loaded: shape = (1000, 13)\n",
      "batch_948.pkl loaded: shape = (1000, 13)\n",
      "batch_949.pkl loaded: shape = (1000, 13)\n",
      "batch_95.pkl loaded: shape = (1000, 13)\n",
      "batch_950.pkl loaded: shape = (1000, 13)\n",
      "batch_951.pkl loaded: shape = (1000, 13)\n",
      "batch_952.pkl loaded: shape = (1000, 13)\n",
      "batch_953.pkl loaded: shape = (1000, 13)\n",
      "batch_954.pkl loaded: shape = (1000, 13)\n",
      "batch_955.pkl loaded: shape = (1000, 13)\n",
      "batch_956.pkl loaded: shape = (1000, 13)\n",
      "batch_957.pkl loaded: shape = (1000, 13)\n",
      "batch_958.pkl loaded: shape = (1000, 13)\n",
      "batch_959.pkl loaded: shape = (1000, 13)\n",
      "batch_96.pkl loaded: shape = (1000, 13)\n",
      "batch_960.pkl loaded: shape = (1000, 13)\n",
      "batch_961.pkl loaded: shape = (1000, 13)\n",
      "batch_962.pkl loaded: shape = (1000, 13)\n",
      "batch_963.pkl loaded: shape = (1000, 13)\n",
      "batch_964.pkl loaded: shape = (1000, 13)\n",
      "batch_965.pkl loaded: shape = (1000, 13)\n",
      "batch_966.pkl loaded: shape = (1000, 13)\n",
      "batch_967.pkl loaded: shape = (1000, 13)\n",
      "batch_968.pkl loaded: shape = (1000, 13)\n",
      "batch_969.pkl loaded: shape = (1000, 13)\n",
      "batch_97.pkl loaded: shape = (1000, 13)\n",
      "batch_970.pkl loaded: shape = (1000, 13)\n",
      "batch_971.pkl loaded: shape = (1000, 13)\n",
      "batch_972.pkl loaded: shape = (1000, 13)\n",
      "batch_973.pkl loaded: shape = (1000, 13)\n",
      "batch_974.pkl loaded: shape = (1000, 13)\n",
      "batch_975.pkl loaded: shape = (1000, 13)\n",
      "batch_976.pkl loaded: shape = (1000, 13)\n",
      "batch_977.pkl loaded: shape = (1000, 13)\n",
      "batch_978.pkl loaded: shape = (1000, 13)\n",
      "batch_979.pkl loaded: shape = (1000, 13)\n",
      "batch_98.pkl loaded: shape = (1000, 13)\n",
      "batch_980.pkl loaded: shape = (1000, 13)\n",
      "batch_981.pkl loaded: shape = (1000, 13)\n",
      "batch_982.pkl loaded: shape = (1000, 13)\n",
      "batch_983.pkl loaded: shape = (1000, 13)\n",
      "batch_984.pkl loaded: shape = (1000, 13)\n",
      "batch_985.pkl loaded: shape = (1000, 13)\n",
      "batch_986.pkl loaded: shape = (1000, 13)\n",
      "batch_987.pkl loaded: shape = (1000, 13)\n",
      "batch_988.pkl loaded: shape = (1000, 13)\n",
      "batch_989.pkl loaded: shape = (1000, 13)\n",
      "batch_99.pkl loaded: shape = (1000, 13)\n",
      "batch_990.pkl loaded: shape = (1000, 13)\n",
      "batch_991.pkl loaded: shape = (1000, 13)\n",
      "batch_992.pkl loaded: shape = (1000, 13)\n",
      "batch_993.pkl loaded: shape = (1000, 13)\n",
      "batch_994.pkl loaded: shape = (1000, 13)\n",
      "batch_995.pkl loaded: shape = (1000, 13)\n",
      "batch_996.pkl loaded: shape = (1000, 13)\n",
      "batch_997.pkl loaded: shape = (1000, 13)\n",
      "batch_998.pkl loaded: shape = (1000, 13)\n",
      "batch_999.pkl loaded: shape = (1000, 13)\n",
      "All .pkl files loaded. Final shape: (913000, 13)\n"
     ]
    }
   ],
   "source": [
    "folder = \"/root/output_folder/reviews\"  # Make sure this is the folder with .pkl batches\n",
    "df_r = []\n",
    "\n",
    "for fname in sorted(os.listdir(folder)):\n",
    "    if fname.endswith(\".pkl\"):\n",
    "        try:\n",
    "            file_path = os.path.join(folder, fname)\n",
    "            review_df = pd.read_pickle(file_path)\n",
    "            print(f\"{fname} loaded: shape = {review_df.shape}\")\n",
    "            df_r.append(review_df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in {fname}:\", e)\n",
    "\n",
    "if df_r:\n",
    "    full_review_Amazon_df = pd.concat(df_r, ignore_index=True)\n",
    "    print(\"All .pkl files loaded. Final shape:\", full_review_Amazon_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67a1227",
   "metadata": {},
   "source": [
    "Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a6b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_meta_review_df = pd.merge(\n",
    "    full_review_Amazon_df,\n",
    "    full_meta_Amazon_df,\n",
    "    on=\"parent_asin\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "amazon_meta_review_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fa5c94",
   "metadata": {},
   "source": [
    "Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  1. Load the reviews and metadata\n",
    "# print(\" Loading Parquet files...\")\n",
    "# reviews = pd.read_parquet(\"root/output_folder/reviews.parquet\")\n",
    "# meta = pd.read_parquet(\"root/output_folder/meta.parquet\")\n",
    "# print(f\" Reviews shape: {reviews.shape}\")\n",
    "# print(f\" Metadata shape: {meta.shape}\")\n",
    "\n",
    "# #  2. Merge on 'parent_asin'\n",
    "# print(\" Merging on parent_asin...\")\n",
    "# merged = pd.merge(reviews, meta, on=\"parent_asin\", how=\"inner\", suffixes=(\"_review\", \"_meta\"))\n",
    "# print(f\" Merged shape: {merged.shape}\")\n",
    "\n",
    "# #  3a. Drop rows with invalid or missing ratings\n",
    "# print(\" Filtering invalid ratings...\")\n",
    "# merged = merged[merged[\"rating\"].between(1.0, 5.0, inclusive=\"both\")]\n",
    "\n",
    "# #  3b. Drop rows with empty or missing review text\n",
    "# print(\" Dropping empty review text...\")\n",
    "# merged = merged[merged[\"text\"].notna() & (merged[\"text\"].str.strip() != \"\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f63611d",
   "metadata": {},
   "source": [
    "Dealing with the brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b227198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_brand(details, store):\n",
    "#     try:\n",
    "#         if isinstance(details, dict) and \"brand\" in details and details[\"brand\"]:\n",
    "#             return details[\"brand\"]\n",
    "#     except Exception:\n",
    "#         pass\n",
    "#     if isinstance(store, str) and store.strip():\n",
    "#         return store\n",
    "#     return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7c1eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #dealing with brand  data\n",
    "# # 3c. Extract brand (from details or store) or set to \"Unknown\"\n",
    "# print(\" Extracting brand from metadata...\")\n",
    "# merged[\"brand\"] = merged.apply(lambda row: extract_brand(row.get(\"details\"), row.get(\"store\")), axis=1)\n",
    "\n",
    "# #  4. Remove duplicates: (user id, asin, text)\n",
    "# print(\" Removing duplicate reviews...\")\n",
    "# merged.drop_duplicates(subset=[\"user id\", \"asin\", \"text\"], keep=\"first\", inplace=True)\n",
    "\n",
    "# #  5a. Derived column: review_length (token count)\n",
    "# print(\" Computing review length...\")\n",
    "# merged[\"review_length\"] = merged[\"text\"].str.split().apply(len)\n",
    "\n",
    "# #  5b. Derived column: year (from timestamp)\n",
    "# print(\" Extracting year from timestamp...\")\n",
    "# merged[\"year\"] = pd.to_datetime(merged[\"timestamp\"], unit=\"s\", errors=\"coerce\").dt.year\n",
    "\n",
    "# #  6. Save cleaned data\n",
    "# output_path = \"root/output_folder/cleaned_merged.parquet\"\n",
    "# print(f\" Saving cleaned dataset to: {output_path}\")\n",
    "# merged.to_parquet(output_path, index=False)\n",
    "\n",
    "# print(\" All cleaning steps completed.\")\n",
    "# print(f\" Final dataset shape: {merged.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1c30a3",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74773e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_meta = Dataset.from_file(\"/root/Code/root/Data/temp_extract/raw_meta_Gift_Cards/full/data-00000-of-00001.arrow\")\n",
    "# ds_review = Dataset.from_file(\"/root/Code/root/Data/temp_extract/raw_review_Gift_Cards/full/data-00000-of-00001.arrow\")\n",
    "# ds_review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fc4c2a",
   "metadata": {},
   "source": [
    "Dead Code (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c95544",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Combine review files\n",
    "    # review_files = [f for f in arrow_files if \"meta\" not in str(f)]\n",
    "    # combined_review_file = f\"{temp_path}/combined_reviews.arrow\"\n",
    "    # print(combined_review_file)\n",
    "    # combine_arrow_files(review_files, combined_review_file)\n",
    "\n",
    "    # # Combine meta files\n",
    "    # meta_files = [f for f in arrow_files if \"meta\" in str(f)]\n",
    "    # combined_meta_file = f\"{temp_path}/combined_meta.arrow\"\n",
    "    # print(combined_meta_file)\n",
    "    # combine_arrow_files(meta_files, combined_meta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207a450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import col, size, split, year, from_unixtime, when, lit\n",
    "# from datasets import Dataset\n",
    "# import pyarrow.json as pajson\n",
    "# import pyarrow.dataset as ds\n",
    "# import pyarrow as pa\n",
    "# import pyarrow.parquet as pq\n",
    "# import json\n",
    "\n",
    "\n",
    "# def preprocess_category(review_tar_path, meta_tar_path, output_folder):\n",
    "#     temp_path = \"root/Data/temp_extract\"\n",
    "#     if os.path.exists(temp_path):\n",
    "#         shutil.rmtree(temp_path)\n",
    "#     os.makedirs(temp_path, exist_ok=True)\n",
    "\n",
    "#     print(\"attempting to call extract function...\")\n",
    "#     extract_tar_bz2(review_tar_path, temp_path)\n",
    "#     extract_tar_bz2(meta_tar_path, temp_path)\n",
    "\n",
    "#     # finding the json files and reading\n",
    "#     print(\"Finding Arrow files...\")\n",
    "#     arrow_files = list(Path(temp_path).rglob(\"*.arrow\"))\n",
    "#     print(f\"Found Arrow files: {arrow_files}\")\n",
    "\n",
    "#     # print the length of the arrow files\n",
    "#     print(len(arrow_files))\n",
    "#     review_file = []\n",
    "#     meta_file = []\n",
    "\n",
    "#     # review_file.append([f for f in arrow_files if \"meta\" not in str(f)][0])\n",
    "#     # meta_file = [f for f in arrow_files if \"meta\" in str(f)][0]\n",
    "\n",
    "#     # print(review_file)\n",
    "#     test_df = pd.DataFrame()\n",
    "\n",
    "#     for arrow_file in arrow_files:\n",
    "#         try:\n",
    "#             table = Dataset.from_file(str(arrow_file))\n",
    "#             test_df = table.to_pandas()\n",
    "#             print(\"Successful!\")\n",
    "#     #         test_df = spark.createDataFrame(table.to_pandas())\n",
    "#     #         if \"meta\" in str(arrow_file):\n",
    "#     #             metadata_frames.append(df)\n",
    "#     #         else:\n",
    "#     #             review_frames.append(df)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing file {arrow_file}: {e}\")\n",
    "\n",
    "#     print(test_df)\n",
    "    \n",
    "\n",
    "#     # Combine all metadata and review dataframes\n",
    "#     # metadata_df = metadata_frames[0]\n",
    "#     # for frame in metadata_frames[1:]:\n",
    "#     #     metadata_df = metadata_df.union(frame)\n",
    "\n",
    "#     # review_df = review_frames[0]\n",
    "#     # for frame in review_frames[1:]:\n",
    "#     #     review_df = review_df.union(frame)\n",
    "\n",
    "\n",
    "\n",
    "#     # # Load the combined JSON files into Spark DataFrames\n",
    "#     # reviews_df = spark.read.json(combined_review_file)\n",
    "#     # meta_df = spark.read.json(combined_meta_file)\n",
    "\n",
    "#     # reviews_df.show()\n",
    "#     # meta_df.show()\n",
    "#     # Load with pyarrow and convert to Spark DataFrame\n",
    "#     # reviews_df = spark.createDataFrame(pajson.read_json(str(review_file)).to_pandas())  # Use pyarrow to read JSON\n",
    "#     # meta_df = spark.createDataFrame(pajson.read_json(str(meta_file)).to_pandas())  # Use pyarrow to read JSON\n",
    "#     # reviews_df = spark.read.schema(review_schema).json(str(review_file))  # Use pyarrow to read JSON\n",
    "#     # meta_df = spark.read.schema(meta_schema).json(str(meta_file))  # Use pyarrow to read JSON\n",
    "\n",
    "#     # Assuming 'asin' is present in both DataFrames, we join on it\n",
    "#     # df = reviews_df.join(meta_df, on='parent_asin', how='inner') \n",
    "\n",
    "#     # # # load with Spark\n",
    "#     # reviews_df = spark.read.json(str(review_file))\n",
    "#     # meta_df = spark.read.json(str(meta_file))\n",
    "\n",
    "#     # # print(reviews_df)\n",
    "#     # reviews_df.show()\n",
    "\n",
    "#     # # merge on 'parent_asin'\n",
    "#     # df = reviews_df.join(meta_df, on='parent_asin', how='inner')\n",
    "\n",
    "#     # # drop rows with invalid ratings or empty text\n",
    "#     # df = df.filter((col(\"rating\").between(1, 5)) &\n",
    "#     #                (col(\"text\").isNotNull()) &\n",
    "#     #                (col(\"text\") != \"\"))\n",
    "\n",
    "#     # # brand logic\n",
    "#     # df = df.withColumn(\n",
    "#     #     \"brand\",\n",
    "#     #     when(col(\"details.brand\").isNotNull(), col(\"details.brand\"))\n",
    "#     #     .when(col(\"store\").isNotNull(), col(\"store\"))\n",
    "#     #     .otherwise(lit(\"Unknown\"))\n",
    "#     # )\n",
    "\n",
    "#     # # derived columns\n",
    "#     # df = df.withColumn(\"review_length\", size(split(col(\"text\"), \" \")))\n",
    "#     # df = df.withColumn(\"year\", year(from_unixtime(col(\"timestamp\"))))\n",
    "\n",
    "#     # # drop duplicates (based on user_id, asin, text)\n",
    "#     # df = df.dropDuplicates([\"user_id\", \"asin\", \"text\"])\n",
    "\n",
    "#     # # save as Parquet\n",
    "#     # category = Path(review_tar_path).stem.replace(\"raw_review_\", \"\")\n",
    "#     # output_file = os.path.join(output_folder, f\"cleaned_{category}.parquet\")\n",
    "#     # df.write.mode(\"overwrite\").parquet(output_file)\n",
    "\n",
    "#     # shutil.rmtree(temp_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c681d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json \n",
    "# def combine_json_files(json_files, output_file):\n",
    "#     combined_data = []\n",
    "#     for file in json_files:\n",
    "#         with open(file, 'r', encoding='utf-8', errors='replace') as f:\n",
    "#             try:\n",
    "#                 data = json.load(f)\n",
    "#                 if isinstance(data, list):  # If the JSON is an array\n",
    "#                     combined_data.extend(data)\n",
    "#                 else:  # If the JSON is an object\n",
    "#                     combined_data.append(data)\n",
    "#             except json.JSONDecodeError as e:\n",
    "#                 print(f\"Error decoding JSON from file {file}: {e}\")\n",
    "    \n",
    "#     # Save the combined data to a new JSON file\n",
    "#     with open(output_file, 'w', encoding='utf-8') as f:\n",
    "#         json.dump(combined_data, f, indent=4)\n",
    "#     print(f\"Combined JSON saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
