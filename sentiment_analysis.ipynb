{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde6ba0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning 33 files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 1,376,163\n",
      "\n",
      "=== Binary Sentiment Classification Results ===\n",
      "Accuracy     : 0.8890\n",
      "F1 Score     : 0.9307\n",
      "Confusion Matrix:\n",
      "[[ 39423  21012]\n",
      " [  9551 205247]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Path to your cleaned dataset\n",
    "CLEANED_DIR = \"/root/deduped_mix\"\n",
    "all_files = glob.glob(os.path.join(CLEANED_DIR, \"*_merged.parquet\"))\n",
    "\n",
    "print(f\"Scanning {len(all_files)} files...\")\n",
    "\n",
    "sample_rows = 100000 \n",
    "dfs = []\n",
    "\n",
    "for f in all_files:\n",
    "    try:\n",
    "        df = duckdb.sql(f\"\"\"\n",
    "            SELECT text, rating\n",
    "            FROM read_parquet('{f}', union_by_name=True)\n",
    "            WHERE rating BETWEEN 1 AND 5 AND text IS NOT NULL\n",
    "            USING SAMPLE BERNOULLI(0.3 PERCENT)\n",
    "            LIMIT {sample_rows}\n",
    "        \"\"\").df()\n",
    "        \n",
    "        df = df[df[\"text\"].str.strip().astype(bool)]\n",
    "        df[\"sentiment\"] = (df[\"rating\"] > 3).astype(int)\n",
    "        dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipped {os.path.basename(f)}: {e}\")\n",
    "\n",
    "if not dfs:\n",
    "    raise RuntimeError(\"No valid data loaded.\")\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True).sample(frac=1.0, random_state=42)\n",
    "print(f\"Total samples: {len(df):,}\")\n",
    "\n",
    "# TF-IDF vectorization (exact criteria)\n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    stop_words='english',\n",
    "    min_df=5,\n",
    "    max_df=0.8,  # 80% max document frequency\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df[\"text\"])\n",
    "y = df[\"sentiment\"]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Logistic Regression classifier\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"\\n=== Binary Sentiment Classification Results ===\")\n",
    "print(f\"Accuracy     : {acc:.4f}\")\n",
    "print(f\"F1 Score     : {f1:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{cm}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
